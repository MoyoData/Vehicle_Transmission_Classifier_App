{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJQE7FrzvsW0"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix,ConfusionMatrixDisplay\n",
        "from sklearn.impute import SimpleImputer # Import the SimpleImputer class from the correct module\n",
        "from sklearn.pipeline import Pipeline  # Import Pipeline for creating the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = []\n",
        "models.append(('LR', LogisticRegression(solver ='lbfgs',multi_class='auto')))\n",
        "models.append(('KNN', KNeighborsClassifier()))\n",
        "models.append(('NB', GaussianNB()))\n",
        "models.append(('SVC', SVC(gamma='scale')))\n",
        "models.append(('RFC', RandomForestClassifier(n_estimators=100)))\n",
        "models.append(('DTR', DecisionTreeClassifier()))\n",
        "models.append(('XGB',XGBClassifier()))"
      ],
      "metadata": {
        "id": "Mhu-Nyi_v7Mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "names = []"
      ],
      "metadata": {
        "id": "1VSxdMVbv_dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "\n",
        "# Ensure target variable is numeric\n",
        "if y_resampled.dtype == 'object':\n",
        "    le = LabelEncoder()\n",
        "    y_resampled = le.fit_transform(y_resampled)\n",
        "\n",
        "# Scale features BEFORE converting to NumPy\n",
        "scaler = StandardScaler()\n",
        "scaled_X_train_resampled_combined = scaler.fit_transform(scaled_X_train_resampled_combined)\n",
        "\n",
        "# Convert feature set and target variable to NumPy array\n",
        "X_array = np.array(scaled_X_train_resampled_combined, dtype=np.float32)  # Ensure XGB compatibility\n",
        "y_array = np.array(y_resampled, dtype=np.int32)  # Ensure consistent int dtype\n",
        "\n",
        "# Define models\n",
        "models = [\n",
        "    ('Logistic Regression', LogisticRegression(max_iter=500)),\n",
        "    ('Random Forest', RandomForestClassifier(n_jobs=-1, class_weight={0:1, 1:1.5})),  # Boost recall for manual\n",
        "    ('XGB', XGBClassifier(eval_metric='logloss', n_jobs=-1, use_label_encoder=False))\n",
        "]\n",
        "\n",
        "# Set up K-Fold cross-validation\n",
        "kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# Run cross-validation\n",
        "for name, model in models:\n",
        "    if name == \"XGB\":\n",
        "        # Manually perform K-Fold for XGB\n",
        "        accuracies = []\n",
        "        for train_idx, test_idx in kfold.split(X_array):\n",
        "            X_train, X_test = X_array[train_idx], X_array[test_idx]\n",
        "            y_train, y_test = y_array[train_idx], y_array[test_idx]\n",
        "\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "            accuracies.append(accuracy_score(y_test, y_pred))\n",
        "\n",
        "        print(f\"{name}: {np.mean(accuracies):.4f}\")\n",
        "    else:\n",
        "        cv_results = cross_val_score(model, X_array, y_array, cv=kfold, scoring='accuracy')\n",
        "        print(f\"{name}: {cv_results.mean():.4f}\")\n"
      ],
      "metadata": {
        "id": "T7-SKm2cwDXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Hyperparameter Tuning**\n",
        "Since RandomForestClassifier is the best performing model based on the cross-validation results, we will be be performimg hyperparameter tuning to identify the best hyperparameter for prediction."
      ],
      "metadata": {
        "id": "UvD8BinBwH3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyper parameter tuning of random forest regressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import mean_squared_error\n"
      ],
      "metadata": {
        "id": "o_mpdjSdwHix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Instantiating\n",
        "RF = RandomForestClassifier()\n",
        "\n",
        "# Default parameters\n",
        "RF.get_params()"
      ],
      "metadata": {
        "id": "LeH1wOSJwM4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameter grid to search\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 150, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'bootstrap': [True, False],\n",
        "    'max_features': ['sqrt', 'log2'],\n",
        "    'bootstrap': [True, False],\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "W85QBy6owR9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Random Forest Regressor\n",
        "rf_regressor = RandomForestClassifier()\n",
        "\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "grid_search = GridSearchCV(estimator=rf_regressor,\n",
        "                           param_grid=param_grid, cv=3,\n",
        "                           scoring='precision',\n",
        "                           n_jobs=-1, verbose=2 )"
      ],
      "metadata": {
        "id": "oPOZlhEIwUjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the GridSearchCV object to the training data\n",
        "grid_search.fit(scaled_X_train_resampled_combined, y_resampled)\n",
        "\n",
        "#Use the best estimator from grid search\n",
        "best_rf = grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "mEAE96MqwXdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_rf"
      ],
      "metadata": {
        "id": "7rI3U7zXwcAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure target variable is numeric\n",
        "if y_resampled.dtype == 'object':\n",
        "    le = LabelEncoder()\n",
        "    y_resampled = le.fit_transform(y_resampled)\n",
        "\n",
        "# Check if scaled_X_train_resampled_combined is a DataFrame\n",
        "if isinstance(scaled_X_train_resampled_combined, pd.DataFrame):\n",
        "    training_feature_names = list(scaled_X_train_resampled_combined.columns)\n",
        "else:\n",
        "    # Try retrieving from test set if train set is already NumPy\n",
        "    if isinstance(scaled_X_test_resampled_combined, pd.DataFrame):\n",
        "        training_feature_names = list(scaled_X_test_resampled_combined.columns)\n",
        "    else:\n",
        "        raise ValueError(\"Feature names are lost! Use the original DataFrame before conversion.\")\n",
        "\n",
        "# Convert feature set and target variable to NumPy arrays\n",
        "scaled_X_train_resampled_combined = np.array(scaled_X_train_resampled_combined)\n",
        "y_array = np.array(y_resampled)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "scaled_X_train_resampled_combined = scaler.fit_transform(scaled_X_train_resampled_combined)\n",
        "\n",
        "# Convert X_test to NumPy and ensure it has correct feature names\n",
        "scaled_X_test_resampled_combined = scaler.transform(scaled_X_test_resampled_combined)  # Apply same scaling\n",
        "scaled_X_test_resampled_combined = pd.DataFrame(scaled_X_test_resampled_combined, columns=training_feature_names)\n",
        "\n",
        "# Train the best model and make predictions\n",
        "best_rf = grid_search.fit(scaled_X_train_resampled_combined, y_array).best_estimator_\n",
        "y_pred = best_rf.predict(scaled_X_test_resampled_combined)\n"
      ],
      "metadata": {
        "id": "qZ5eE51dwgBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, make predictions\n",
        "y_pred = best_rf.predict(X_test)"
      ],
      "metadata": {
        "id": "ezAjD4VIwkgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(scaled_y1_resampled_df) == len(y_pred):\n",
        "    accuracy = accuracy_score(scaled_y1_resampled_df, y_pred)\n",
        "    print(f\"Accuracy of the best model on the test dataset: {accuracy:.4f}\")\n",
        "else:\n",
        "    print(f\" Length mismatch: scaled_y1_resampled_df={len(scaled_y1_resampled_df)}, y_pred={len(y_pred)}\")\n"
      ],
      "metadata": {
        "id": "LdMqVJICwo6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the performance of the best model on the test dataset\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy of the best model on the test dataset: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "3-1nLMzfwr8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the performance of the best model on the test dataset\n",
        "accuracy = accuracy_score(y_test, y_pred)  # Use y_test instead of y_resampled\n",
        "print(f\"Accuracy of the best model on the test dataset: {accuracy:.4f}\")\n",
        "\n",
        "# Generate classification report and confusion matrix\n",
        "print(classification_report(y_test, y_pred))  # Use y_test\n",
        "cm = confusion_matrix(y_test, y_pred)  # Use y_test\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n"
      ],
      "metadata": {
        "id": "2c6JunrcwvYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can also visualize the confusion matrix using ConfusionMatrixDisplay\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lVapl4Z6wzMt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}